---
title: "SpeciesListCleaning"
author: "Beth Davis"
date: "2022-11-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# November 2022
Load in abbagadabba
```{r}
library(devtools)
install_github("Maine-eDNA/abbagadabba")

library(abbagadabba)
```

Read in the GBIF simple file (the species list was attempted but had an error and they should have the same taxonomy results so ignoring that error for now)

```{r}
simple <- read.table('~/Research/GBIFNovSimple.csv', sep = '\t', fill = TRUE, header = TRUE)
#slist <- read.table('~/Research/GBIFNovSpeciesList.csv', sep = '\t', fill = TRUE, header = TRUE)
```

Check the columns to make sure column selection is right and select all unique values for the species only (originally this was all taxonomy ranks and this resulted in the GBIFTaxa.csv file)

```{r}
#head(simple)

# Check that I can pull out just the taxonomic ranks
#head(simple[, 10])

GBIFspecies <- unique(simple[, 10])
```

Save the extracted unique species names to a separate dataframe and .csv

```{r}
GBIFResults <- as.data.frame(GBIFspecies)
write.csv(GBIFspecies, '~/Research/GBIFSpecies.csv')
```

Read in the non-GBIF data

```{r}
source <- read.csv('~/Desktop/SpeciesListMetatest.csv', header = TRUE)
```

Check and make sure all the data read in correctly

```{r}
tail(source)
```

Pull the unique values out and save to a new .csv

```{r}
sourcetaxa <- unique(source[, 1])
write.csv(sourcetaxa, '~/Research/NonGBIFTaxa.csv')
```

Clean taxa files and combine

```{r}
# cource sourcetaxa to a dataframe
sourcedspecies <- as.data.frame(sourcetaxa)
```

```{r}
head(GBIFResults)
head(sourcedspecies)

colnames(GBIFResults) <- c('Species')
colnames(sourcedspecies) <- c('Species')

head(GBIFResults)
head(sourcedspecies)
```

```{r}
results <- rbind(GBIFResults, sourcedspecies)

uniqueresults <- unique(results)
```

```{r}
write.csv(uniqueresults, '~/Research/MaineSpeciesList.csv')
```


# Continue on 2/21/2023 with the following goals:

* Run the species list through the abbagadabba cleaning codes and add on the other taxonomic ranks
* remove case insensitive duplicates
* Create a 'species_binomial' column for use in Erin's code

```{r listload, include = FALSE}
speclist <- readLines('C:/Users/bydav/Desktop/RefLib/MaineSpeciesList_Clean.csv')

subsettest <- read.csv('C:/Users/bydav/Desktop/RefLib/MaineSpeciesList_Clean_Subset.csv')

```

```{r}
if (!require("rentrez")) {install.packages("rentrez"); require("rentrez")} # Query ENTREZ databases and download accessions
set_entrez_key("")
```

Think this should work, but hold off on running it on the full list until the cleaning of duplicates is done
```{r cleannames, include = FALSE}
testvec <- c('Idiomyia sproati', 'Drosophil murphy', 'no body')

specvec <- as.vector(speclist)

for (i in specvec) {
  x3 <- getNCBITaxonomy(i)
  print(x3)
}
```

```{r capital_test, include = FALSE}
library(stringr)

MaineDeDupList <- str_to_sentence(specvec, locale = "en")

MaineDeDupList
```

Now recheck for unique only


```{r}
MaineUnique2 <- unique(MaineDeDupList)
MaineUnique2

colnames(MaineSpecList) <- 'species_binomial'

MaineSpecList <- as.data.frame(MaineSpecList)
MaineSpecListUnique <- write.csv(MaineSpecList, "C:/Users/bydav/Desktop/RefLib/MaineSpecListUnique.csv")
```

Now run taxonomy
```{r}
#MaineTaxa_Test <- data.frame(kingdom=NA, phylum=NA, class=NA, order=NA, suborder=NA, infraorder = NA, superfamily = NA, family = NA, subfamily = NA, tribe = NA, genus = NA, species = NA, species_binomial = NA, old_name = NA, ncbi_name = NA, uid = NA) 

MaineTaxa_Test1 = 0


for (row in 1:nrow(MaineSpecList)) {
    for (col in 1:ncol(MaineSpecList)) {
        print(paste('Row', row, 'col', col, 'value', MaineSpecList[row, col]))
    }
}


for (i in MaineSpecList) {
  taxa <- getNCBITaxonomy(i)
  print(taxa)
}



```

Had to make some edits (change colnames and remove first row) from the species list. Wiping the environment and starting over from here

```{r}
listfull <- read.csv('C:/Users/bydav/Desktop/RefLib/MaineSpecListUnique.csv')
listset <- read.csv('C:/Users/bydav/Desktop/RefLib/MaineSpeciesList_Clean_Subset.csv')

library(abbagadabba)
library(stringr)
```


```{r}
for (i in listfull) {
  taxa <- getNCBITaxonomy(i)
  print(i) #counter
  print(taxa)
}

taxatest <- as.data.frame(taxa)
```


# July 11, 2023
BYD

Goals:
Continue cleaning the species list (need to deal with capitalization inconsistencies (done), check for special characters (done), remove everything that isn't a 2 word species binomial (done), and remove duplicates again)

Write a little chunk to add new species to the list (and maybe record the row numbers so that downstream scripts and functions can also be run without having to rerun the entire document? Or should it be the other way around - run the to-be-added file first and then append?)


(using scan so it imports as a vector)
```{r import_full_list, echo = FALSE}
library(dplyr)
library(tidyr)
library(stringr)

encodetest <- scan("C:/Users/bydav/Desktop/MaineSpeciesList_Clean.csv", sep=',', what = "", quiet = TRUE, encoding = "latin1")
```
```{r cases, echo = FALSE}

# fix capitalization
encodes <- str_to_sentence(encodetest)
```

```{r binomial, echo = FALSE}

# I give up on doing regexp searches and replaces. Breaking the vector of names into a dataframe, separating by space so I can just join only the first two columns
encodetable <- as.data.frame(encodes) %>% separate(encodes, into = paste("column", 1:23, sep = " "))

# join the binomial back together
encodetable$source_binomial <- paste0(encodetable$`column 1`, sep=" ", encodetable$`column 2`)

# check for special characters and check results for any trues
pattern <- "/|:|\\?|<|>|\\|\\\\|\\*"

results <- grepl(pattern, encodetable$source_binomial)
```

I can't get (genus sp) or (genus cf) removed - keeping in for now, input requested

```{r genera, echo = FALSE}
# pick out just the genera 
generalist <- encodetable$`column 1`

# find only the unique genera
genera <- unique(generalist)
MaineGenera <- write.csv(genera, "C:/Users/bydav/Desktop/MaineGenera.csv")

```

```{r unique_export, echo = FALSE}
# remove uniques and export to a new file
encodeunique <- unique(encodetable$source_binomial)

cleanlist <- write.csv(encodeunique, "C:/Users/bydav/Desktop/CleanSpecies.csv")
```



# March 8, 2024

What is the best way to keep the source metadata with the species name so it's searchable in maybe a shiny app table?

## Load packages
```{r loadpackages}
library(beepr) # to notify when long chunks are done
library(dplyr) # for cleaning
library(tidyverse) # for cleaning
library(taxize) # for taxonomy
library(rotl) # for taxonomy
library(stringi) # for cleaning
```

Load in the SpeciesList_MetaShareable file (as .csv, only the first tab)
```{r loadin}
listbase <- read.csv("C:/Users/bydav/Desktop/SpeciesListMeta.csv", header = TRUE, encoding = 'UTF-8')
```

We want to remove the bacteria and fungi. Easiest way to do that is remove all rows where I know the source was those taxa-specific sources, then can do further cleaning once the higher taxonomy is assigned
```{r eukaryaonly}
eukaryalist <- subset(listbase, !(Source %in% c(2,3,16)))

# specieslist without the removals:
eukaryalist <- listbase
```

There are 2 problems. In order to fill out the higher taxonomy, it'll be easiest to remove the sources so the list can be deduplicated, and the higher taxonomy can be searched and added without being as massive a list. However, then I need to re-add the sources somehow. I'll first try to compress the source information into a single row. If that's possible, the list can be simplified to unique occurrences while still preserving the source metadata.

This chunk tests the different steps involved in consolidating and maintaining the source metadata 
```{r sourceloop_testing}
# Initial query on a species I know has more than one source to test the search function
eukaryalist[eukaryalist$Species_Name == "Salmo salar", ]

# Attach search result to a new dataframe
df <- data.frame(SpeciesBinomial = c("Salmo salar"))

# Manually attach the source values to the dataframe
df$SourceList <- list(c(1,5,13))

# Check dataframe
df


# Take one step back and now try another species, without the manual additions
# Assign search result to a variable
x <- eukaryalist[eukaryalist$Species_Name == "Syringa vulgaris", ]

# Check that variable components can be called
x$Species_Name
x$Source

# Append results to the dataframe
df[nrow(df) + 1,] = c(x$Species_Name, x$Source)

# Test again with a species that should have at least 2 sources
y <- eukaryalist[eukaryalist$Species_Name == "Petromyzon marinus", ]

# Assign source values to a list
ysource <- list(c(y$Source))

# Check list
ysource

# Append search results, specifying only one instance of the name is needed, to the dataframe. Keep the source as 0 so it can be filled in later. Adding directly does not work
df[nrow(df) + 1,] = c(unique(y$Species_Name), 0)

# Attach the source list to the latest row
df[nrow(df), ]$SourceList <- ysource

# Check results
df
```


Now that the steps are built, make a loop and fill in a new dataframe with the species binomial and source information
```{r sourceloop}
# Create a list of unique names
filter <- unique(eukaryalist$Species_Name)

# prep a new dataframe
metadf <- data.frame(matrix(ncol = 2, nrow = 0))
colnames(metadf) <- c('SpeciesBinomial', 'SourceList')
metadf

# Loop to fill in the new dataframe with species and source info
for (i in filter) {
  tempsearch <- eukaryalist[eukaryalist$Species_Name == i, ]
  tempsource <- list(c(tempsearch$Source))
  metadf[nrow(metadf) + 1,] = c(unique(tempsearch$Species_Name), 0)
  metadf[nrow(metadf), ]$SourceList <- tempsource
}

# convert source column to character, then v to read it back in as a list (as a function)
paste(collapse = ";")

# notify when done
beep(sound = "wilhelm")
```

Save this intermediate list before we add the GBIF data.
```{r save_intermediate}
saveRDS(metadf, file = "C:\\Users\\bydav\\Desktop\\nonGBIFlist.RDS")

# RDS files can be called with readRDS(file = "")
nonGBIFlist = readRDS(file = "C:\\Users\\bydav\\Desktop\\SpeciesList_Cleaning2024/nonGBIFlist.RDS")
```

This doesn't include the taxa from GBIF though. With the loop running, I can pull in the GBIF data file, extract only the unique species names, assign them a source ID, and merge with the eukaryalist, then re-run the loop. 

Using the same GBIF version for consistency, found here: https://doi.org/10.15468/dl.vjz7em 

```{r appendGBIF}
GBIF <- read.table('C:/Users/bydav/Desktop/SpeciesList_Cleaning2024/GBIFNovSpeciesList.csv', sep = '\t', fill = TRUE, header = TRUE, encoding = 'UTF-8')

# Only pull the species names - we don't need any other info here
GBIFspecies <- unique(GBIF[, 10])

# Coerce to dataframe
GBIFResults <- as.data.frame(GBIFspecies)

# Update column name
colnames(GBIFResults) <- c("SpeciesBinomial")

??colnames

# add a column for "Source" and add 29 (the source code for GBIF) to each row
GBIFdf <- GBIFResults %>%
  mutate(SourceList = 29)


head(GBIFdf)
# Append the GBIF list to our eukaryalist and set a notification for when it's done
updatedeukarya <- (rbind(GBIFdf, nonGBIFlist))
beep(sound = "fanfare")


head(updatedeukarya)
```

```{r fulllist_sourceloop}

# Create a list of unique names
filter2 <- unique(updatedeukarya$SpeciesBinomial)

# prep a new dataframe
metadf2 <- data.frame(matrix(ncol = 2, nrow = 0))
colnames(metadf2) <- c('SpeciesBinomial', 'SourceList')
metadf2


for (i in filter2) {
  tempsearch <- updatedeukarya[updatedeukarya$SpeciesBinomial == i, ]
  tempsource <- list(c(tempsearch$SourceList))
  metadf2[nrow(metadf2) + 1,] = c(unique(tempsearch$SpeciesBinomial), 0)
  metadf2[nrow(metadf2), ]$SourceList <- tempsource
}

beep(sound = "wilhelm")
```


Now that the lists are combined, we'll go back in to deal with lingering cleaning issues
```{r fulllist_cleaning}

# Remove all rows that don't have any whitespace - this should remove the Genus-only entries
speciesqc <- metadf2 %>% filter(str_detect(str_trim(SpeciesBinomial), "\\s+"))

# Force encoding
speciesqc$SpeciesBinomial<- stri_trans_general(speciesqc$SpeciesBinomial, "latin-ascii")

# Trim leading and tailing spaces
speciesqc$SpeciesBinomial <- trimws(speciesqc$SpeciesBinomial, which = c("both"))

#There are several entries that contain varieties of 'unknown' that we want to remove. Define vector of strings
exeunt <- c('Unknown', 'Unidentified', 'Undetermined', 'Undetermiend')

  #remove rows that contain any string in the vector in the team column
speciesqc <- speciesqc[!grepl(paste(exeunt, collapse='|'), speciesqc$SpeciesBinomial),]

# Remove all symbols/characters that aren't spaces or alphanumeric characters - from rominger_codathon
speciesqc$SpeciesBinomial <- gsub("[^[:alnum:][:space:]]", "", speciesqc$SpeciesBinomial)

speciesqc <- speciesqc[!grepl('sp\\.|cf\\.|f\\.', speciesqc$SpeciesBinomial), , drop = FALSE]

# Papilio canadensis X glaucus causes an Internal Server Error for some reason. Not related to either a lone character or a long string. 
# Try overwriting it.

# Identify which row it's in
speciesqc[speciesqc$SpeciesBinomial == "Papilio canadensis X glaucus", ]
# Overwrite
speciesqc[24219, 1] = "Papilio canadensis glaucus"

# Save the cleaned output as another RDS
#saveRDS(updatedeukarya, file = "C:\\Users\\bydav\\Desktop\\updatedspecieslist.RDS")
```

Check validity of names, especially cleaning up typos. Can set the vectors as large as 1000, but use smaller intervals for troubleshooting and checking where errors occur
```{r fulllist_gnrresolve}
# break-up names into vectors of at most 500
splitNames <- split(speciesqc$SpeciesBinomial, 
                    ceiling(seq_along(speciesqc$SpeciesBinomial)/1000))


# make a list to populate with results from `gnr_resolve`
xclean <- vector('list', length(splitNames))

sources <- c(4, 9, 11, 12, 44)

for(i in 1:length(xclean)) {  
  # `preferred_data_source = 4` is for NCBI
  # set `http = 'post'` for large query
  xclean[[i]] <- gnr_resolve(splitNames[[i]], 
                             resolve_once = TRUE, preferred_data_sources = sources,
                             best_match_only = TRUE, 
                             canonical = TRUE, http = 'post', fields = "all")
  cat('# ----\n')
  cat(i, '\n')
  print(dim(xclean[[i]]))
  cat(' \n')
}
beep(sound = "wilhelm")


sourcefull <- gnr_datasources()
# Save as an intermediate RDS
saveRDS(xclean, file = "C:\\Users\\bydav\\Desktop\\GNRSpList.RDS")
```

Need to now convert xclean back to a dataframe so we can continue - code adapted from Erin's naming script
```{r fullist_dfcoerce}
splist01 <- as.data.frame(xclean[[1]])
splist02 <- as.data.frame(xclean[[2]])
splist03 <- as.data.frame(xclean[[3]])
splist04 <- as.data.frame(xclean[[4]])
splist05 <- as.data.frame(xclean[[5]])
splist06 <- as.data.frame(xclean[[6]])
splist07 <- as.data.frame(xclean[[7]])
splist08 <- as.data.frame(xclean[[8]])
splist09 <- as.data.frame(xclean[[9]])
splist10 <- as.data.frame(xclean[[10]])
splist11 <- as.data.frame(xclean[[11]])
splist12 <- as.data.frame(xclean[[12]])
splist13 <- as.data.frame(xclean[[13]])
splist14 <- as.data.frame(xclean[[14]])
splist15 <- as.data.frame(xclean[[15]])
splist16 <- as.data.frame(xclean[[16]])
splist17 <- as.data.frame(xclean[[17]])
splist18 <- as.data.frame(xclean[[18]])
splist19 <- as.data.frame(xclean[[19]])
splist20 <- as.data.frame(xclean[[20]])
splist21 <- as.data.frame(xclean[[21]])
splist22 <- as.data.frame(xclean[[22]])
splist23 <- as.data.frame(xclean[[23]])
splist24 <- as.data.frame(xclean[[24]])
splist25 <- as.data.frame(xclean[[25]])
splist26 <- as.data.frame(xclean[[26]])
splist27 <- as.data.frame(xclean[[27]])
splist28 <- as.data.frame(xclean[[28]])
splist29 <- as.data.frame(xclean[[29]])

splist <- rbind(splist01, splist02, splist03, splist04, splist05, splist06, splist07, splist08, splist09, splist10, splist11, splist12, splist13, splist14, splist15,splist16, splist17, splist18, splist19, splist20, splist21, splist22, splist23, splist24, splist25, splist26, splist27, splist28, splist29)

# Separate the ones with different numbers of columns
splistv2 <- rbind(splist01, splist03, splist05, splist06, splist07, splist08, splist12, splist13, splist15, splist16, splist17)

splistv1 <- rbind(splist02, splist04, splist09, splist10, splist11, splist14, splist18, splist19, splist20, splist21, splist22, splist23, splist24, splist25, splist26, splist27, splist28, splist29)


splistv11 <- subset(splistv1[1:17])

splist <- rbind(splistv11, splistv2)

head(splist18[18])
#saveRDS(splist, file = "C:\\Users\\bydav\\Desktop\\GNRSpDF.RDS")
```


```{r fulllist_format}
# Update formatting for match_value and match_type
splist$match_value <- as.factor(splist$match_value)
splist$match_type <- as.factor(splist$match_type)

# Taxa that could only be identified to genus + deduplication
splist_GenusOnly <- subset(splist, match_value == "Could only match genus")
# fill in genus name
splist_GenusOnly$genus <- vapply(strsplit(splist_GenusOnly$matched_name," "), `[`, 1, FUN.VALUE=character(1)) 
splist_UniqueGenusOnly <- splist_GenusOnly[!duplicated(splist_GenusOnly$genus),]

# Taxa that could be identified to species + deduplication
splist_Species <- subset(splist, match_value != "Could only match genus")
splist_UniqueSpecies <- splist_Species[!duplicated(splist_Species$matched_name),]
splist_UniqueSpecies$superkingdom <- "na"; splist_UniqueSpecies$kingdom <- "na"; 
splist_UniqueSpecies$phylum <- "na"; splist_UniqueSpecies$class <- "na";
splist_UniqueSpecies$order <- "na"; splist_UniqueSpecies$family <- "na";
splist_UniqueSpecies$genus <- "na"; splist_UniqueSpecies$species <- "na"

s=1
for (s in 1:dim(splist_UniqueSpecies)[1]) {
  paths <- unlist(strsplit(splist_UniqueSpecies$classification_path[s], "|", fixed=TRUE))
  ranks <- unlist(strsplit(splist_UniqueSpecies$classification_path_ranks[s], "|", fixed=TRUE))                
  temp <- as.data.frame(cbind(paths, ranks))
  
  if (length(which(temp$ranks=="superkingdom"))>0){
  splist_UniqueSpecies$superkingdom[s] <- temp[which(temp$ranks=="superkingdom"), 1]
  }
  if (length(which(temp$ranks=="kingdom"))>0){
  splist_UniqueSpecies$kingdom[s] <- temp[which(temp$ranks=="kingdom"), 1]
  }
  if (length(which(temp$ranks=="phylum"))>0){
  splist_UniqueSpecies$phylum[s] <- temp[which(temp$ranks=="phylum"), 1]
  }
  if (length(which(temp$ranks=="class"))>0){
  splist_UniqueSpecies$class[s] <- temp[which(temp$ranks=="class"), 1]
  }
  if (length(which(temp$ranks=="order"))>0){
  splist_UniqueSpecies$order[s] <- temp[which(temp$ranks=="order"), 1]
  }
  if (length(which(temp$ranks=="family"))>0){
  splist_UniqueSpecies$family[s] <- temp[which(temp$ranks=="family"), 1]
  }
  if (length(which(temp$ranks=="genus"))>0){
  splist_UniqueSpecies$genus[s] <- temp[which(temp$ranks=="genus"), 1]
  }
  if (length(which(temp$ranks=="species"))>0){
  splist_UniqueSpecies$species[s] <- temp[which(temp$ranks=="species"), 1]
  }
  
  rm(paths, ranks, temp)
  s=s+1
}
beep(sound = "fanfare")

# Save the splist_UniqueGenusOnly and splist_UniqueSpecies outputs
saveRDS(splist_UniqueGenusOnly, file = "C:\\Users\\bydav\\Desktop\\GNRSpList_GenusOnly.RDS")
saveRDS(splist_UniqueSpecies, file = "C:\\Users\\bydav\\Desktop\\GNRSpList_Species.RDS")
```

The remaining cleaning steps we want are to check which species entries from speciesqc didn't find a gnr_resolve match and were left out, to reconnect the source metadata for the species that were found, and create species lists that don't include bacteria and/or fungi
```{r fulllist_isolate}

# Locate the species binomials that were left out after GNR resolve.
sp_unID <- setdiff(speciesqc$SpeciesBinomial, splist_UniqueSpecies$user_supplied_name)
saveRDS(sp_unID, file = "C:\\Users\\bydav\\Desktop\\Unidentified_Species.RDS")

# Add source info to the GNR_resolved names
SpList_wSource <- inner_join(
  splist_UniqueSpecies,
  speciesqc,
  by = join_by(user_supplied_name == SpeciesBinomial),
  na_matches = c("never"),
  multiple = "first",
  unmatched = "drop",
  relationship = "many-to-many"
)

# Save full output
saveRDS(splist_UniqueSpecies, file = "C://Users//bydav//Desktop//GNRMaineSpeciesList.RDS")
  
# pick out just the found species to test with Erin's workflow:
write.csv(subset(splist_UniqueSpecies[8]), "C://Users//bydav//Desktop//SpeciesOnly.csv") 


# Remove bacteria but not fungi
eukaryota <- subset(SpList_wSource, superkingdom == "Eukaryota")

# Save output without bacteria
saveRDS(eukaryota, file = "C:\\Users\\bydav\\Desktop\\GNREukaryotaList.RDS")

# Remove fungi but not bacteria
nofungusamongus <- subset(SpList_wSource, kingdom != "Fungi")

# Save output without fungi
saveRDS(nofungusamongus, file = "C:\\Users\\bydav\\Desktop\\GNRNoFungusSpeciesList.RDS")

# Remove bacteria and not fungi
clean_eukaryota <- subset(eukaryota, kingdom != "Fungi")

# Save output without bacteria
saveRDS(clean_eukaryota, file = "C:\\Users\\bydav\\Desktop\\GNREukaryota_NoFungus.RDS")
```



## 5/14 - redoing the species list cleaning to test something

```{r fulllist_sourceloop}
# loading in appropriate/required libraries
library(stringr)
library(stringi)
library(beepr)

# Loading in the saved object from March 8 created after joining the meta species list and GBIF list
updatedeukarya <- updatedspecieslist

# Force data object to encode as latin-ascii
updatedeukarya$Species_Name<- stri_trans_general(updatedeukarya$Species_Name, "latin-ascii")

# Remove all symbols/characters that aren't spaces or alphanumeric characters - from rominger_codathon
updatedeukarya$Species_Name <- gsub("[^[:alnum:][:space:]]", "", updatedeukarya$Species_Name)

updatedeukarya <- updatedeukarya[!grepl('sp\\.|cf\\.|f\\.', updatedeukarya$Species_Name), , drop = FALSE]

# There are several entries that contain varieties of 'unknown' that we want to remove. Define vector of strings
exeunt <- c('Unknown', 'Unidentified', 'Undetermined', 'Undetermiend')

# remove rows that contain any string in the vector in the team column
updatedeukarya <- updatedeukarya[!grepl(paste(exeunt, collapse='|'), updatedeukarya$Species_Name),]

# Trim leading and tailing spaces
updatedeukarya$Species_Name <- trimws(updatedeukarya$Species_Name, which = c("both"))

# Remove all rows that don't have any whitespace - this should remove the Genus-only entries
updatedeukarya <- updatedeukarya[grepl('\\s+', updatedeukarya$Species_Name),]

# Fix capitalization
updatedeukarya$Species_Name = str_to_lower(updatedeukarya$Species_Name)
updatedeukarya$Species_Name = str_to_sentence(updatedeukarya$Species_Name)

# Create a list of unique names
filter2 <- unique(updatedeukarya$Species_Name)

# prep a new dataframe
metadf2 <- data.frame(matrix(ncol = 2, nrow = 0))
colnames(metadf2) <- c('SpeciesBinomial', 'SourceList')

# Consolidate sources into single column list
for (i in filter2) {
  tempsearch <- updatedeukarya[updatedeukarya$Species_Name == i, ]
  tempsource <- list(c(tempsearch$Source))
  metadf2[nrow(metadf2) + 1,] = c(unique(tempsearch$Species_Name), 0)
  metadf2[nrow(metadf2), ]$SourceList <- tempsource
}

# inform when finished running
beep(sound = "wilhelm")

# rename object for easier reference later
speciesqc <- metadf2
```


Now that the lists are combined, we'll go back in to deal with lingering cleaning issues
```{r fulllist_cleaning}

# Papilio canadensis X glaucus causes an Internal Server Error for some reason. Not related to either a lone character or a long string. 
# Try overwriting it.

# Identify which row it's in
speciesqc[speciesqc$SpeciesBinomial == "Papilio canadensis x glaucus", ]

# Overwrite
speciesqc[24158, 1] = "Papilio canadensis glaucus"

# Convert the SourceList column from lists to character strings, and remove the 'c' (mitigates future read issues)
speciesqc$SourceList <- as.character(speciesqc$SourceList)
speciesqc$SourceList <- gsub('c', '', speciesqc$SourceList)


# Save the cleaned output as another RDS and a csv
saveRDS(speciesqc, file = "C:\\Users\\bydav\\Desktop\\MaineSpeciesListClean_May2024.RDS")
write.csv(speciesqc, "C:\\Users\\bydav\\Desktop\\MaineSpeciesListClean_May2024.csv")

```

Check validity of names, especially cleaning up typos. Can set the vectors as large as 1000, but use smaller intervals for troubleshooting and checking where errors occur
```{r fulllist_gnrresolve}
speciesqc <- readRDS("C:\\Users\\bydav\\Desktop\\MaineSpeciesListClean_May2024.RDS")

# break-up names into vectors of at most 500
splitNames <- split(speciesqc$SpeciesBinomial, 
                    ceiling(seq_along(speciesqc$SpeciesBinomial)/1000))


# make an empty list object equal to populate with results from `gnr_resolve`
xclean <- vector('list', length(splitNames))

# identify which database sources for gnr_resolve to search from - these numbers come from the gnr_resolve documentation
sources <- c(4, 9, 11, 12, 44)

# for each list in xclean, run the gnr_resolver to search the selected databases for species taxonomy matches and keep only the best match. Results will populate into xclean
for(i in 1:length(xclean)) {  
  # `preferred_data_source = 4` is for NCBI
  # set `http = 'post'` for large query
  xclean[[i]] <- gnr_resolve(splitNames[[i]], 
                             resolve_once = TRUE, preferred_data_sources = sources,
                             best_match_only = TRUE, 
                             canonical = TRUE, http = 'post', fields = "all")
  cat('# ----\n')
  cat(i, '\n')
  print(dim(xclean[[i]]))
  cat(' \n')
}
beep(sound = "wilhelm")

# Save as an intermediate RDS
saveRDS(xclean, file = "C:\\Users\\bydav\\Desktop\\GNRSpListresults_May2024.RDS")
```

Need to now convert xclean back to a dataframe so we can continue - code adapted from Erin's naming script
```{r fullist_dfcoerce}
splist01 <- as.data.frame(xclean[[1]])
splist02 <- as.data.frame(xclean[[2]])
splist03 <- as.data.frame(xclean[[3]])
splist04 <- as.data.frame(xclean[[4]])
splist05 <- as.data.frame(xclean[[5]])
splist06 <- as.data.frame(xclean[[6]])
splist07 <- as.data.frame(xclean[[7]])
splist08 <- as.data.frame(xclean[[8]])
splist09 <- as.data.frame(xclean[[9]])
splist10 <- as.data.frame(xclean[[10]])
splist11 <- as.data.frame(xclean[[11]])
splist12 <- as.data.frame(xclean[[12]])
splist13 <- as.data.frame(xclean[[13]])
splist14 <- as.data.frame(xclean[[14]])
splist15 <- as.data.frame(xclean[[15]])
splist16 <- as.data.frame(xclean[[16]])
splist17 <- as.data.frame(xclean[[17]])
splist18 <- as.data.frame(xclean[[18]])
splist19 <- as.data.frame(xclean[[19]])
splist20 <- as.data.frame(xclean[[20]])
splist21 <- as.data.frame(xclean[[21]])
splist22 <- as.data.frame(xclean[[22]])
splist23 <- as.data.frame(xclean[[23]])
splist24 <- as.data.frame(xclean[[24]])
splist25 <- as.data.frame(xclean[[25]])
splist26 <- as.data.frame(xclean[[26]])
splist27 <- as.data.frame(xclean[[27]])
splist28 <- as.data.frame(xclean[[28]])
splist29 <- as.data.frame(xclean[[29]])

# Separate the ones with different numbers of columns
splist_19s <- rbind(splist02, splist04, splist09, splist10, splist11, splist14, splist18, splist19, splist20, splist21, splist22, splist23, splist24, splist25, splist26, splist27, splist28, splist29)

splist_17s <- rbind(splist01, splist03, splist05, splist06, splist07, splist08, splist12, splist13, splist15, splist16, splist17)

# trim off excess columns
splist_19trim <- subset(splist_19s[1:17])

splist <- rbind(splist_17s, splist_19trim)

saveRDS(splist, file = "C:\\Users\\bydav\\Desktop\\GNRSpListResults_Dataframe_May2024.RDS")
```


```{r fulllist_format}
# Update formatting for match_value and match_type
splist$match_value <- as.factor(splist$match_value)
splist$match_type <- as.factor(splist$match_type)

# Taxa that could only be identified to genus + deduplication
splist_GenusOnly <- subset(splist, match_value == "Could only match genus")
# fill in genus name
splist_GenusOnly$genus <- vapply(strsplit(splist_GenusOnly$matched_name," "), `[`, 1, FUN.VALUE=character(1)) 
splist_UniqueGenusOnly <- splist_GenusOnly[!duplicated(splist_GenusOnly$genus),]

# Taxa that could be identified to species + deduplication
splist_Species <- subset(splist, match_value != "Could only match genus")
splist_UniqueSpecies <- splist_Species[!duplicated(splist_Species$matched_name),]
splist_UniqueSpecies$superkingdom <- "na"; splist_UniqueSpecies$kingdom <- "na"; 
splist_UniqueSpecies$phylum <- "na"; splist_UniqueSpecies$class <- "na";
splist_UniqueSpecies$order <- "na"; splist_UniqueSpecies$family <- "na";
splist_UniqueSpecies$genus <- "na"; splist_UniqueSpecies$species <- "na"

# taken from Erin's code, checks for empty taxonomy cells
# set counter
s=1
for (s in 1:dim(splist_UniqueSpecies)[1]) {
  paths <- unlist(strsplit(splist_UniqueSpecies$classification_path[s], "|", fixed=TRUE))
  ranks <- unlist(strsplit(splist_UniqueSpecies$classification_path_ranks[s], "|", fixed=TRUE))                
  temp <- as.data.frame(cbind(paths, ranks))
  
  if (length(which(temp$ranks=="superkingdom"))>0){
  splist_UniqueSpecies$superkingdom[s] <- temp[which(temp$ranks=="superkingdom"), 1]
  }
  if (length(which(temp$ranks=="kingdom"))>0){
  splist_UniqueSpecies$kingdom[s] <- temp[which(temp$ranks=="kingdom"), 1]
  }
  if (length(which(temp$ranks=="phylum"))>0){
  splist_UniqueSpecies$phylum[s] <- temp[which(temp$ranks=="phylum"), 1]
  }
  if (length(which(temp$ranks=="class"))>0){
  splist_UniqueSpecies$class[s] <- temp[which(temp$ranks=="class"), 1]
  }
  if (length(which(temp$ranks=="order"))>0){
  splist_UniqueSpecies$order[s] <- temp[which(temp$ranks=="order"), 1]
  }
  if (length(which(temp$ranks=="family"))>0){
  splist_UniqueSpecies$family[s] <- temp[which(temp$ranks=="family"), 1]
  }
  if (length(which(temp$ranks=="genus"))>0){
  splist_UniqueSpecies$genus[s] <- temp[which(temp$ranks=="genus"), 1]
  }
  if (length(which(temp$ranks=="species"))>0){
  splist_UniqueSpecies$species[s] <- temp[which(temp$ranks=="species"), 1]
  }
  
  rm(paths, ranks, temp)
  s=s+1
}
beep(sound = "fanfare")

# Save the splist_UniqueGenusOnly and splist_UniqueSpecies outputs
saveRDS(splist_UniqueGenusOnly, file = "C:\\Users\\bydav\\Desktop\\GNRSpList_GenusOnly_May2024.RDS")
saveRDS(splist_UniqueSpecies, file = "C:\\Users\\bydav\\Desktop\\GNRSpList_Species_May2024.RDS")
```

The remaining cleaning steps we want are to check which species entries from speciesqc didn't find a gnr_resolve match and were left out, to reconnect the source metadata for the species that were found, and create species lists that don't include bacteria and/or fungi
```{r fulllist_isolate}

# Locate the species binomials that were left out after GNR resolve.
sp_unID <- setdiff(speciesqc$SpeciesBinomial, splist_UniqueSpecies$user_supplied_name)
saveRDS(sp_unID, file = "C:\\Users\\bydav\\Desktop\\UnidentifiedSpecies_May2024.RDS")

# Add source info to the GNR_resolved names
SpList_wSource <- inner_join(
  splist_UniqueSpecies,
  speciesqc,
  by = join_by(user_supplied_name == SpeciesBinomial),
  na_matches = c("never"),
  multiple = "first",
  unmatched = "drop",
  relationship = "many-to-many"
)

# Save full output
saveRDS(SpList_wSource, file = "C://Users//bydav//Desktop//GNRMaineSpecies_May2024.RDS")
  
# pick out just the found species to test with Erin's workflow:
#write.csv(subset(splist_UniqueSpecies[8]), "C://Users//bydav//Desktop//SpeciesOnly.csv") 


# Remove bacteria but keep fungi
eukaryota <- subset(SpList_wSource, superkingdom == "Eukaryota")

# Save output without bacteria
saveRDS(eukaryota, file = "C:\\Users\\bydav\\Desktop\\GNREukaryotaList_May2024.RDS")

# Remove fungi but keep bacteria
nofungusamongus <- subset(SpList_wSource, kingdom != "Fungi")

# Save output without fungi
saveRDS(nofungusamongus, file = "C:\\Users\\bydav\\Desktop\\GNRNoFungusSpeciesList_May2024.RDS")

# Remove bacteria and fungi
clean_eukaryota <- subset(eukaryota, kingdom != "Fungi")

# Save output without bacteria or fungi
saveRDS(clean_eukaryota, file = "C:\\Users\\bydav\\Desktop\\GNREukaryota_NoFungus_May2024.RDS")
```












