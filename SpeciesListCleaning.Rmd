---
title: "SpeciesListCleaning"
author: "Beth Davis"
date: "2022-11-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# November 2022
Load in abbagadabba
```{r}
library(devtools)
install_github("Maine-eDNA/abbagadabba")

library(abbagadabba)
```

Read in the GBIF simple file (the species list was attempted but had an error and they should have the same taxonomy results so ignoring that error for now)

```{r}
simple <- read.table('~/Research/GBIFNovSimple.csv', sep = '\t', fill = TRUE, header = TRUE)
#slist <- read.table('~/Research/GBIFNovSpeciesList.csv', sep = '\t', fill = TRUE, header = TRUE)
```

Check the columns to make sure column selection is right and select all unique values for the species only (originally this was all taxonomy ranks and this resulted in the GBIFTaxa.csv file)

```{r}
#head(simple)

# Check that I can pull out just the taxonomic ranks
#head(simple[, 10])

GBIFspecies <- unique(simple[, 10])
```

Save the extracted unique species names to a separate dataframe and .csv

```{r}
GBIFResults <- as.data.frame(GBIFspecies)
write.csv(GBIFspecies, '~/Research/GBIFSpecies.csv')
```

Read in the non-GBIF data

```{r}
source <- read.csv('~/Desktop/SpeciesListMetatest.csv', header = TRUE)
```

Check and make sure all the data read in correctly

```{r}
tail(source)
```

Pull the unique values out and save to a new .csv

```{r}
sourcetaxa <- unique(source[, 1])
write.csv(sourcetaxa, '~/Research/NonGBIFTaxa.csv')
```

Clean taxa files and combine

```{r}
# cource sourcetaxa to a dataframe
sourcedspecies <- as.data.frame(sourcetaxa)
```

```{r}
head(GBIFResults)
head(sourcedspecies)

colnames(GBIFResults) <- c('Species')
colnames(sourcedspecies) <- c('Species')

head(GBIFResults)
head(sourcedspecies)
```

```{r}
results <- rbind(GBIFResults, sourcedspecies)

uniqueresults <- unique(results)
```

```{r}
write.csv(uniqueresults, '~/Research/MaineSpeciesList.csv')
```


# Continue on 2/21/2023 with the following goals:

* Run the species list through the abbagadabba cleaning codes and add on the other taxonomic ranks
* remove case insensitive duplicates
* Create a 'species_binomial' column for use in Erin's code

```{r listload, include = FALSE}
speclist <- readLines('C:/Users/bydav/Desktop/RefLib/MaineSpeciesList_Clean.csv')

subsettest <- read.csv('C:/Users/bydav/Desktop/RefLib/MaineSpeciesList_Clean_Subset.csv')

```

```{r}
if (!require("rentrez")) {install.packages("rentrez"); require("rentrez")} # Query ENTREZ databases and download accessions
set_entrez_key("c832cec80a76de1a62694193df8eb51d6608")
```

Think this should work, but hold off on running it on the full list until the cleaning of duplicates is done
```{r cleannames, include = FALSE}
testvec <- c('Idiomyia sproati', 'Drosophil murphy', 'no body')

specvec <- as.vector(speclist)

for (i in specvec) {
  x3 <- getNCBITaxonomy(i)
  print(x3)
}
```

```{r capital_test, include = FALSE}
library(stringr)

MaineDeDupList <- str_to_sentence(specvec, locale = "en")

MaineDeDupList
```

Now recheck for unique only


```{r}
MaineUnique2 <- unique(MaineDeDupList)
MaineUnique2

colnames(MaineSpecList) <- 'species_binomial'

MaineSpecList <- as.data.frame(MaineSpecList)
MaineSpecListUnique <- write.csv(MaineSpecList, "C:/Users/bydav/Desktop/RefLib/MaineSpecListUnique.csv")
```

Now run taxonomy
```{r}
#MaineTaxa_Test <- data.frame(kingdom=NA, phylum=NA, class=NA, order=NA, suborder=NA, infraorder = NA, superfamily = NA, family = NA, subfamily = NA, tribe = NA, genus = NA, species = NA, species_binomial = NA, old_name = NA, ncbi_name = NA, uid = NA) 

MaineTaxa_Test1 = 0


for (row in 1:nrow(MaineSpecList)) {
    for (col in 1:ncol(MaineSpecList)) {
        print(paste('Row', row, 'col', col, 'value', MaineSpecList[row, col]))
    }
}


for (i in MaineSpecList) {
  taxa <- getNCBITaxonomy(i)
  print(taxa)
}



```

Had to make some edits (change colnames and remove first row) from the species list. Wiping the environment and starting over from here

```{r}
listfull <- read.csv('C:/Users/bydav/Desktop/RefLib/MaineSpecListUnique.csv')
listset <- read.csv('C:/Users/bydav/Desktop/RefLib/MaineSpeciesList_Clean_Subset.csv')

library(abbagadabba)
library(stringr)
```


```{r}
for (i in listfull) {
  taxa <- getNCBITaxonomy(i)
  print(i) #counter
  print(taxa)
}

taxatest <- as.data.frame(taxa)
```


# July 11, 2023
BYD

Goals:
Continue cleaning the species list (need to deal with capitalization inconsistencies (done), check for special characters (done), remove everything that isn't a 2 word species binomial (done), and remove duplicates again)

Write a little chunk to add new species to the list (and maybe record the row numbers so that downstream scripts and functions can also be run without having to rerun the entire document? Or should it be the other way around - run the to-be-added file first and then append?)


(using scan so it imports as a vector)
```{r import_full_list, echo = FALSE}
library(dplyr)
library(tidyr)
library(stringr)

encodetest <- scan("C:/Users/bydav/Desktop/MaineSpeciesList_Clean.csv", sep=',', what = "", quiet = TRUE, encoding = "latin1")
```
```{r cases, echo = FALSE}

# fix capitalization
encodes <- str_to_sentence(encodetest)
```

```{r binomial, echo = FALSE}

# I give up on doing regexp searches and replaces. Breaking the vector of names into a dataframe, separating by space so I can just join only the first two columns
encodetable <- as.data.frame(encodes) %>% separate(encodes, into = paste("column", 1:23, sep = " "))

# join the binomial back together
encodetable$source_binomial <- paste0(encodetable$`column 1`, sep=" ", encodetable$`column 2`)

# check for special characters and check results for any trues
pattern <- "/|:|\\?|<|>|\\|\\\\|\\*"

results <- grepl(pattern, encodetable$source_binomial)
```

I can't get (genus sp) or (genus cf) removed - keeping in for now, input requested

```{r genera, echo = FALSE}
# pick out just the genera 
generalist <- encodetable$`column 1`

# find only the unique genera
genera <- unique(generalist)
MaineGenera <- write.csv(genera, "C:/Users/bydav/Desktop/MaineGenera.csv")

```

```{r unique_export, echo = FALSE}
# remove uniques and export to a new file
encodeunique <- unique(encodetable$source_binomial)

cleanlist <- write.csv(encodeunique, "C:/Users/bydav/Desktop/CleanSpecies.csv")
```



# March 8, 2024

What is the best way to keep the source metadata with the species name so it's searchable in maybe a shiny app table?

load packages
```{r loadpackage}
library(beepr)
library(dplyr)
library(tidyverse)
library(taxize)
library(rotl)
library(stringi)
```

Load in the SpeciesList_MetaShareable file (as .csv, only the first tab)
```{r loadin}
listbase <- read.csv("C:/Users/bydav/Desktop/SpeciesListMeta.csv", header = TRUE, encoding = 'UTF-8')
```

We want to remove the bacteria and fungi. Easiest way to do that is remove all rows where I know the source was those taxa-specific sources, then can do further cleaning once the higher taxonomy is assigned
```{r}
eukaryalist <- subset(listbase, !(Source %in% c(2,3,16)))
```

There are 2 problems. In order to fill out the higher taxonomy, it'll be easiest to remove the sources so the list can be deduplicated, and the higher taxonomy can be searched and added without being as massive a list. However, then I need to re-add the sources somehow. I'll first try to compress the source information into a single row. If that's possible, the list can be simplified to unique occurrences while still preserving the source metadata.


```{r teststeps}
# Initial query on a species I know has more than one source to test the search function
eukaryalist[eukaryalist$Species_Name == "Salmo salar", ]

# Attach search result to a new dataframe
df <- data.frame(SpeciesBinomial = c("Salmo salar"))

# Manually attach the source values to the dataframe
df$SourceList <- list(c(1,5,13))

# Check dataframe
df


# Take one step back and now try another species, without the manual additions
# Assign search result to a variable
x <- eukaryalist[eukaryalist$Species_Name == "Syringa vulgaris", ]

# Check that variable components can be called
x$Species_Name
x$Source

# Append results to the dataframe
df[nrow(df) + 1,] = c(x$Species_Name, x$Source)

# Test again with a species that should have at least 2 sources
y <- eukaryalist[eukaryalist$Species_Name == "Petromyzon marinus", ]

# Assign source values to a list
ysource <- list(c(y$Source))

# Check list
ysource

# Append search results, specifying only one instance of the name is needed, to the dataframe. Keep the source as 0 so it can be filled in later. Adding directly does not work
df[nrow(df) + 1,] = c(unique(y$Species_Name), 0)

# Attach the source list to the latest row
df[nrow(df), ]$SourceList <- ysource

# Check results
df
```


Now that the steps are built, make a loop and fill in a new dataframe
```{r}
# Create a list of unique names
filter <- unique(eukaryalist$Species_Name)

# prep a new dataframe
metadf <- data.frame(matrix(ncol = 2, nrow = 0))
colnames(metadf) <- c('SpeciesBinomial', 'SourceList')
metadf


for (i in filter) {
  tempsearch <- eukaryalist[eukaryalist$Species_Name == i, ]
  tempsource <- list(c(tempsearch$Source))
  metadf[nrow(metadf) + 1,] = c(unique(tempsearch$Species_Name), 0)
  metadf[nrow(metadf), ]$SourceList <- tempsource
}

beep(sound = "wilhelm")
```

figure out how to save this type of result with the list intact
```{r}
library(data.table)

fwrite(metadf, "C:\\Users\\bydav\\Desktop\\eukaryalist.csv")

# this has the source lists as numbers separated with |, which isn't ideal but honestly better than previous attempts.
testload <- read.csv("C:\\Users\\bydav\\Desktop\\eukaryalist.csv")
testload
```


```{r verify}
# Test a search query
metadf[metadf$SpeciesBinomial == "Salmo salar", ]
```

This doesn't include the taxa from GBIF though. With the loop running, I can pull in the GBIF data file, extract only the unique species names, assign them a source ID, and merge with the eukaryalist, then re-run the loop. There was the July list, but it doesn't contain source information, and so I can't tell what's from GBIF and what's not

Using the same GBIF version for consistency, found here: https://doi.org/10.15468/dl.vjz7em 

```{r}
GBIF <- read.table('C:/Users/bydav/Desktop/GBIFNovSpeciesList.csv', sep = '\t', fill = TRUE, header = TRUE, encoding = 'UTF-8')

GBIFspecies <- unique(GBIF[, 10])

GBIFResults <- as.data.frame(GBIFspecies)

colnames(GBIFResults) <- c("Species_Name")

GBIFdf <- GBIFResults %>%
  mutate(Source = 29)

updatedeukarya <- (rbind(GBIFdf, eukaryalist))
beep(sound = "fanfare")

fwrite(updatedeukarya, "C:\\Users\\bydav\\Desktop\\updatedeukaryalist.csv")

```

```{r updatedloop}

# Create a list of unique names
filter2 <- unique(updatedeukarya$Species_Name)

# prep a new dataframe
metadf2 <- data.frame(matrix(ncol = 2, nrow = 0))
colnames(metadf2) <- c('SpeciesBinomial', 'SourceList')
metadf2


for (i in filter2) {
  tempsearch <- updatedeukarya[updatedeukarya$Species_Name == i, ]
  tempsource <- list(c(tempsearch$Source))
  metadf2[nrow(metadf2) + 1,] = c(unique(tempsearch$Species_Name), 0)
  metadf2[nrow(metadf2), ]$SourceList <- tempsource
}

beep(sound = "wilhelm")

head(metadf2)
```


I want to check for any characters in Species_Name that do not belong to the english alphabet
```{r}
letters_only <- function(x) !grepl("[^A-Za-z]", x)

letterresult <- letters_only(metadf2$SpeciesBinomial)

# Get a count of how many have non-letters - 2506
sum(letterresult, na.rm = TRUE)

# Identify some examples to check
which(letterresult)

# looks like a lot of these are rows that only have Genus (not sure why they don't count as letters, but it at least highlights that they're still there)

# Remove all rows that don't have whitespace in the SpeciesBinomial - this should leave us only with the species that have actual species binomials
speciesqc <- metadf2 %>% filter(str_detect(str_trim(SpeciesBinomial), "\\s+"))

# Check for presence of non-letters again
speciesqccheck <- letters_only(speciesqc$SpeciesBinomial)

# Get a count of how many have non-letters - 43
sum(speciesqccheck, na.rm = TRUE)
```


Several are included that are listed as "Unknown <species>" or "Unidentified <species>", "Undetermined", "Undetermiend"
these rows can also be removed

```{r}
#define vector of strings
exeunt <- c('Unknown', 'Unidentified', 'Undetermined', 'Undetermiend')

#remove rows that contain any string in the vector in the team column
speciesqc2 <- speciesqc[!grepl(paste(exeunt, collapse='|'), speciesqc$SpeciesBinomial),]

# Check for weird rows again
#speciesqc2check <- letters_only(speciesqc2$SpeciesBinomial)

# Get a count of how many have non-letters - 2506
#sum(speciesqc2check, na.rm = TRUE)

#which(speciesqc2check)
```
Still finding weird symbols, as well as some . and \ that the letters_only isn't noticing

Borrowing the following from rominger_codathon
```{r}
speciesqc2$SpeciesBinomial<- stri_trans_general(speciesqc2$SpeciesBinomial, "latin-ascii")

speciesqc2 <- speciesqc2[!grepl('sp\\.|cf\\.|f\\.', speciesqc2$SpeciesBinomial), , drop = FALSE]

fwrite(speciesqc2, "C:\\Users\\bydav\\Desktop\\MetaListPreTaxonomy.csv")

```

###########

Check validity of names, especially cleaning up typos
```{r}
# break-up names into vectors of at most 500
splitNames <- split(speciesqc2$SpeciesBinomial, 
                    ceiling(seq_along(speciesqc2$SpeciesBinomial)/500))


# make a list to populate with results from `gnr_resolve`
xclean <- vector('list', length(splitNames))

for(i in 1:length(xclean)) {  
  # `preferred_data_source = 4` is for NCBI
  # set `http = 'post'` for large query
  xclean[[i]] <- gnr_resolve(splitNames[[i]], 
                             resolve_once = TRUE, preferred_data_sources = 4,
                             best_match_only = TRUE, 
                             canonical = TRUE, http = 'post')
  cat('# ----\n')
  cat(i, '\n')
  print(dim(xclean[[i]]))
  cat(' \n')
}
beep(sound = "wilhelm")

# Crashes after 47. not a length issue.

xclean[["1"]]

# higher taxonomy
ranks <- c('kingdom', 'phylum', 'class', 'order', 'family', 'genus', 'species')
tempDF <- as.data.frame(matrix(NA, nrow = 1, ncol = length(ranks)))
names(tempDF) <- ranks

higherTax <- taxizedb::classification(xclean$matched_name2, db = 'ncbi')

??classification

l <- lapply(higherTax, function(r) {
  if(!inherits(r, 'data.frame')) {
    return(tempDF)
  } else {
    y <- r[r$rank %in% ranks, ]
    d <- tempDF
    d[1, y$rank] <- y$name
    
    return(d)
  }
})

taxTable <- do.call(rbind, l)
rownames(taxTable) <- NULL
beep(sound = "wilhelm")
```

####


```
















